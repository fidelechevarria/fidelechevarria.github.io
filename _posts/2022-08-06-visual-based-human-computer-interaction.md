---
layout: post
title: Visual Based Human-Computer Interaction
summary: Developing a desktop application for controlling the computer mouse cursor from detected face movement.
categories: [Computer Vision, Machine Learning]
featured-img: insight
mathjax: false
---

Machine learning is improving the state of the art in many fields of technology. This enables new paradigms in day-to-day tasks that will gradually make a shift in peopleâ€™s lives. One of these emerging fields is visual based human-computer interaction (HCI), which offers huge potential. Many people are not able to use common human-computer interface devices, such as the mouse or keyboard. It is my hope that this emerging field will enable more efficient HCI methods, gradually improving the way we interact with computers.

<figure>
    <p align="center"><img src="/assets/img/article_images/vbhci_001.jpg" width="80%"></p>
    <!-- <figcaption><p align="center"><b>Figure 1</b> - Faces</p></figcaption> -->
</figure>

In this context I have recently released [Lima](https://www.microsoft.com/store/apps/9PGL5GSN68JG), a Microsoft Windows application which allows control of the mouse cursor by detected head movement, facial expressions and voice commands using a standard webcam. There is room for improvement, and more efficient visual based control methods and interactive functionalities to come. The app is now freely available for Windows 10 and 11 through the Microsoft Store, with some premium functionalities. Please feel free to contact at <fidel.echevarria@outlook.com> for any feedback or improvement suggestions if you find it useful.

<script type="module" src="https://get.microsoft.com/badge/ms-store-badge.bundled.js"></script>
<ms-store-badge
productid ="9PGL5GSN68JG"
animation="on"
window-mode="popup"
theme="dark">
</ms-store-badge>
